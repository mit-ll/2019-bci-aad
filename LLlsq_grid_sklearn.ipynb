{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This branch is the software release for the 2019 paper: https://www.nature.com/articles/s41598-019-47795-0\n",
    "\n",
    "See LICENSE.txt\n",
    "\n",
    "Copyright 2019 Massachusetts Institute of Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "from glob import glob\n",
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import getpass\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import datetime\n",
    "import h5py\n",
    "import re\n",
    "import hashlib\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "## Use sklearn for least squares with internal cross validation to reconstruct audio envelopes (b) from eeg (A)\n",
    "#  according to Aw = b.\n",
    "#\n",
    "# For each experiment part, create an A matrix, then concatenate all the parts\n",
    "# a1 a2 a3 a4 ... aN, audio\n",
    "# e1 e2 e3 e4 ... eN, eeg\n",
    "# Assume 26 sample (250 ms window)\n",
    "# Use [e1 .. e26] to predict a1\n",
    "# Therefore, drop the last (26 -1) samples from the audio vector to create the y target vector\n",
    "#\n",
    "## About\n",
    "#  Greg Ciccarelli\n",
    "#  September 3, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as niu\n",
    "import nipype.interfaces.io as nio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def big_node(dct_params):\n",
    "    \"\"\"Main processing function:  performs audio reconstruction from eeg.\n",
    "    \n",
    "    Description\n",
    "    -----------\n",
    "    Unpack parameters\n",
    "    Preproc data and create reconstruction algorithm\n",
    "    Train algorithm and predict on test data\n",
    "    Save out all parameters and predictions\n",
    "    \n",
    "    \"\"\"    \n",
    "    import os\n",
    "    from glob import glob\n",
    "    import scipy\n",
    "    import scipy.io\n",
    "    import scipy.signal\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    import sklearn.metrics\n",
    "    import sklearn.preprocessing\n",
    "    import sklearn.linear_model\n",
    "    import sklearn.datasets\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.model_selection\n",
    "    import datetime\n",
    "    import h5py\n",
    "    import re\n",
    "    import hashlib\n",
    "    import sys\n",
    "    from importlib import reload\n",
    "    \n",
    "    #----------------------------------------------------\n",
    "    #  Unpack Parameters, preproc, create reconstruction alg.\n",
    "    #----------------------------------------------------    \n",
    "    file_path_name_eeg = dct_params['file_path_name_eeg']\n",
    "    file_path_name_audio = dct_params['file_path_name_audio']\n",
    "    train = dct_params['train']\n",
    "    test = dct_params['test']    \n",
    "    alpha_array = dct_params['alpha_array'] \n",
    "    zscore = dct_params['zscore'] \n",
    "    collect = dct_params['collect'] \n",
    "    file_path_name_util = dct_params['file_path_name_util']\n",
    "    idx_ch = dct_params['idx_ch']\n",
    "    num_context = dct_params['num_context']\n",
    "    save_flag = dct_params['save_flag']\n",
    "    file_path_bciaud_shared = dct_params['file_path_bciaud_shared']\n",
    "    timestamp_time  = dct_params['timestamp_time']     \n",
    "    file_path_gridhome = dct_params['file_path_gridhome']\n",
    "    model_lsq = dct_params['model_lsq']\n",
    "    windsor_flag = dct_params['windsor_flag']    \n",
    "    aur_flag = dct_params['aur_flag']\n",
    "    aur_thresh = dct_params['aur_thresh']\n",
    "    loss_type = dct_params['loss_type']\n",
    "    cv_type = dct_params['cv_type']\n",
    "    \n",
    "    sys.path.append(os.path.split(file_path_name_util)[0])\n",
    "    module = __import__(os.path.split(file_path_name_util)[1])\n",
    "    reload(module)\n",
    "    load_data = getattr(module, 'load_data')\n",
    "    cat_part = getattr(module, 'cat_part')\n",
    "    make_conv = getattr(module, 'make_conv') \n",
    "    \n",
    "    audio_ht, eeg_ht, audio_unatt_ht = load_data(file_path_name_audio, file_path_name_eeg)\n",
    "    \n",
    "    ## On the fly preprocessing\n",
    "    if windsor_flag:\n",
    "        prctile = np.nanpercentile(eeg_ht[train], [0.1, 1, 5, 95, 99, 99.9])\n",
    "        #eeg_ht = eeg.copy() #crucial otherwise eeg is overwritten\n",
    "        eeg_ht[eeg_ht < prctile[0]] = prctile[0]\n",
    "        eeg_ht[eeg_ht > prctile[-1]] = prctile[-1]\n",
    "\n",
    "\n",
    "    X_ht, y_ht, z_ht, groups_ht = cat_part(eeg_ht[train], audio_ht[train], audio_unatt_ht[train], \n",
    "                                idx_ch=idx_ch, num_context=num_context)\n",
    "    print(groups_ht) \n",
    "        \n",
    "    Xi, yi, zi = make_conv(eeg_ht[test], audio_ht[test], audio_unatt_ht[test],\n",
    "                           idx_ch=idx_ch, num_context=num_context)\n",
    "\n",
    "    if cv_type == 'sample':\n",
    "        cv_gen = 3\n",
    "        print('-- sample --')\n",
    "    elif cv_type == 'group3fold':\n",
    "        cv_gen = sklearn.model_selection.GroupKFold(n_splits=3).split(X_ht, y_ht, groups=groups_ht)\n",
    "        print('-- part --')\n",
    "    \n",
    "    if loss_type == 'corr':\n",
    "        def score_func(y, y_pred):    \n",
    "            return scipy.stats.pearsonr(np.ravel(y), np.ravel(y_pred))[0]\n",
    "\n",
    "        scoring = sklearn.metrics.make_scorer(score_func, greater_is_better=True, needs_proba=False, needs_threshold=False)\n",
    "        print('-- corr --')\n",
    "        \n",
    "    elif loss_type == 'mse':\n",
    "        scoring = None\n",
    "        print('-- mse --')    \n",
    "    \n",
    "    if model_lsq == 'RidgeCV':\n",
    "        clf = sklearn.linear_model.RidgeCV(alphas=alpha_array, fit_intercept=True, \n",
    "                                           normalize=False, scoring=scoring, cv=cv_gen, \n",
    "                                           gcv_mode=None, store_cv_values=False)\n",
    "    elif model_lsq == 'LassoCV':\n",
    "        #clf = sklearn.linear_model.LassoCV(eps=0.001, n_alphas=100, alphas=None, \n",
    "        #                                   fit_intercept=True, normalize=False, precompute='auto', \n",
    "        #                                   max_iter=10000, tol=0.0001, copy_X=True, cv=3, \n",
    "        #                                   verbose=False, n_jobs=None, positive=False, \n",
    "        #                                   random_state=None, selection='cyclic')\n",
    "        clf = sklearn.linear_model.LassoCV(eps=0.001, alphas=alpha_array,\n",
    "                                           fit_intercept=True, normalize=False, precompute='auto', \n",
    "                                           max_iter=1000, tol=0.0001, copy_X=True, cv=3, \n",
    "                                           verbose=False, n_jobs=None, positive=False, \n",
    "                                           random_state=None, selection='cyclic') \n",
    "        \n",
    "    elif model_lsq == 'RANSAC':\n",
    "        clf = sklearn.linear_model.RANSACRegressor(base_estimator=None, min_samples=None, \n",
    "                                                   residual_threshold=None, is_data_valid=None, \n",
    "                                                   is_model_valid=None, max_trials=100, max_skips=np.inf, \n",
    "                                                   stop_n_inliers=np.inf, stop_score=np.inf, stop_probability=0.99, \n",
    "                                                   loss='absolute_loss', random_state=None)\n",
    "\n",
    "\n",
    "    if zscore == 'RobustScaler':\n",
    "        pp_X = sklearn.preprocessing.RobustScaler()\n",
    "        pp_Y = sklearn.preprocessing.RobustScaler()\n",
    "        pp_Z = sklearn.preprocessing.RobustScaler()\n",
    "    elif zscore == 'StandardScaler':\n",
    "        pp_X = sklearn.preprocessing.StandardScaler() \n",
    "        pp_Y = sklearn.preprocessing.StandardScaler() \n",
    "        pp_Z = sklearn.preprocessing.StandardScaler()\n",
    "    trX_ht  = pp_X.fit_transform(X_ht)\n",
    "    trY_ht = pp_Y.fit_transform(y_ht)\n",
    "    trZ_ht = pp_Z.fit_transform(z_ht)\n",
    "\n",
    "    #----------------------------------------------------\n",
    "    #  Fit and predict audio and EEG\n",
    "    #----------------------------------------------------     \n",
    "    t_start = datetime.datetime.now()\n",
    "    print(trY_ht.shape)\n",
    "    clf.fit(trX_ht, trY_ht)\n",
    "    t_end = datetime.datetime.now()\n",
    "    print('- lsq time -')\n",
    "    print(t_end - t_start)    \n",
    "\n",
    "    y_hat = clf.predict(pp_X.transform(Xi))\n",
    "\n",
    "    #----------------------------------------------------\n",
    "    #  Evaluate and save out\n",
    "    #----------------------------------------------------     \n",
    "    rho_att = scipy.stats.pearsonr(np.ravel(y_hat), np.ravel(pp_Y.transform(yi)))[0]\n",
    "    rho_unatt = scipy.stats.pearsonr(np.ravel(y_hat), np.ravel(pp_Z.transform(zi)))[0]\n",
    "\n",
    "    ####row = np.array([rho_att, rho_unatt])\n",
    "\n",
    "    ###stats[test] = row\n",
    "    #print(clf.alpha_)    \n",
    "    #------------------------------------------------------------------------\n",
    "    example_te_y = np.ravel(pp_Y.transform(yi))\n",
    "    example_te_yhat = np.ravel(y_hat)\n",
    "    example_te_unatt = np.ravel(pp_Z.transform(zi))\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    if collect == 'cocoha':\n",
    "        session_str = '0000'\n",
    "    elif collect == 'Columbia':\n",
    "        session_str = '0000'\n",
    "    else:\n",
    "        session_str = re.search('BCIHearing_Subj_\\d+_([\\d_]+)', file_path_name_eeg).group(1)\n",
    "\n",
    "    dct_all = {\n",
    "                         'envTestAtt': example_te_y[None, :], #output api compatible\n",
    "                         'envHatAtt': example_te_yhat[None, :], #output api compatible\n",
    "                         'envTestUna': example_te_unatt[None, :], #output api compatible\n",
    "                         #'yValAtt': example_val_y,\n",
    "                         #'yValHat': example_val_yhat,\n",
    "                         #'yValUna': example_val_z_unatt,\n",
    "                         #'yTrainAtt': example_tr_y,\n",
    "                         #'yTrainHat': example_tr_yhat,\n",
    "                         #'yTrainUna': example_tr_unatt,\n",
    "                         'yTestAtt': example_te_y,\n",
    "                         'yTestHat': example_te_yhat,\n",
    "                         'yTestUna': example_te_unatt,              \n",
    "                         'subjID': re.search('Subj_(\\d+)_', file_path_name_audio).group(1),#output api compatible\n",
    "                         'alpha': clf.alpha_,\n",
    "                         'rho_att': rho_att,\n",
    "                         'rho_unatt': rho_unatt,\n",
    "                         'file_path_name_net': 'LLlsq_grid_sklearn.ipynb',\n",
    "                          'pp_X_center': pp_X.center_,\n",
    "                          'pp_X_scale': pp_X.scale_,\n",
    "                          'pp_Y_center': pp_Y.center_,\n",
    "                          'pp_Y_scale': pp_Y.scale_,\n",
    "                          'pp_Z_center': pp_Z.center_,\n",
    "                          'pp_Z_scale': pp_Z.scale_,        \n",
    "                         'clf_coef_': clf.coef_,\n",
    "            }\n",
    "    dct_all = {**dct_all, **dct_params}\n",
    "\n",
    "    if save_flag:\n",
    "\n",
    "        timestamp = '%s_%s' % (timestamp_time, \n",
    "                                     hashlib.md5((('').join(file_path_name_audio+file_path_name_eeg)).encode('utf')).hexdigest())\n",
    "\n",
    "        file_path_save = XXX_file_path_save_with_timestamp\n",
    "\n",
    "        # Create the file_path_save here to avoid race conditions in the workflow\n",
    "        if not os.path.exists(file_path_save):\n",
    "            os.makedirs(file_path_save)\n",
    "\n",
    "        hashstr = ''\n",
    "        for key, val in dct_all.items():\n",
    "            if type(val) is str:\n",
    "                hashstr = hashstr + key + val\n",
    "            elif type(val) in [float, int]:\n",
    "                hashstr = hashstr + key + str(val)\n",
    "            elif type(val) in [list]:\n",
    "                if type(val[0]) is str:\n",
    "                    hashstr = hashstr + key + ','.join(val)\n",
    "                elif type(val[0]) in [float, int]:\n",
    "                    hashstr = hashstr + key + ','.join([str(i) for i in val])\n",
    "        hexstamp = hashlib.md5(hashstr.encode('utf')).hexdigest()\n",
    "\n",
    "        now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        file_path_name_checkpoint = os.path.join(file_path_save, \n",
    "                                                 'checkpoint_eeg2env_%s_%s.pt' \n",
    "                                                 % (hexstamp, now_str))\n",
    "\n",
    "        print(file_path_name_checkpoint)\n",
    "        # Replace all None elements of dict with NaN before saving to avoid save fail.\n",
    "        for key, val in dct_all.items():\n",
    "            if val is None:\n",
    "                dct_all[key] = np.nan\n",
    "        scipy.io.savemat(os.path.join(file_path_save, \n",
    "                                      'checkpoint_eeg2env_%s_%s.mat' \n",
    "                                       % (hexstamp, now_str)), \n",
    "                                      dct_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the LSQ model\n",
    "\n",
    "model_lsq = 'RidgeCV'\n",
    "#model_lsq = 'LassoCV'\n",
    "#model_lsq = 'RANSAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "timestamp_time = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# :9 same AM or PM run\n",
    "\n",
    "modality = 'neuroscan'\n",
    "#modality = 'dsi'\n",
    "collect = 'LL_HowTo_0DegreesSeparation'\n",
    "\n",
    "if modality == 'dsi':\n",
    "    idx_ch = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19]) # drop M1 8 and M2 17\n",
    "    #idx_ch = np.arange(20) #keep mastoid\n",
    "elif modality == 'neuroscan':\n",
    "    idx_ch = np.arange(64)\n",
    "    # Subsample the wet eeg to match the dry eeg lead configuration\n",
    "    #idx_ch = [45, 25,  7,  9, 11, 29, 49, 27,  0,  2, 23, 43, 60, 62,  5, 13, 51, 31] # full drop M1 and M2  (32, 42 zero based indexing)\n",
    "    \n",
    "subj_folder_list = XXX_list_of_subject_folders \n",
    "file_path_name_audio_list = XXX_list_of_audio_files\n",
    "file_path_name_eeg_list = XXX_list_of_eeg_files\n",
    "\n",
    "print(file_path_name_audio_list)\n",
    "print(file_path_name_eeg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish preproc and regularization params\n",
    "save_flag = True\n",
    "num_context = 26\n",
    "num_context = 51\n",
    "\n",
    "alpha_array = np.logspace(1, 10, 10) \n",
    "\n",
    "zscore = 'RobustScaler'\n",
    "windsor_flag = False\n",
    "\n",
    "    \n",
    "loss_type = 'mse'\n",
    "loss_type = 'corr'\n",
    "\n",
    "cv_type = 'group3fold'\n",
    "#cv_type = 'sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get helper file\n",
    "file_path_name_util = XXX_path_to_lsq_grid\n",
    "\n",
    "sys.path.append(os.path.split(file_path_name_util)[0])\n",
    "module = __import__(os.path.split(file_path_name_util)[1])\n",
    "reload(module)\n",
    "load_data = getattr(module, 'load_data')\n",
    "cat_part = getattr(module, 'cat_part')\n",
    "make_conv = getattr(module, 'make_conv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cross val folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for file_path_name_audio, file_path_name_eeg in zip(file_path_name_audio_list, file_path_name_eeg_list):\n",
    "    print(file_path_name_audio)\n",
    "    audio, eeg, audio_unatt = load_data(file_path_name_audio, file_path_name_eeg)\n",
    "\n",
    "    # exhaustive\n",
    "    full_set = audio.shape[0]\n",
    "    #full_set = 10 # debug, 4\n",
    "\n",
    "    for test in [33]: #range(full_set): \n",
    "        train = sorted(list(set(range(full_set)) - set([test])))\n",
    "        train = (np.asarray(train)[np.random.permutation(np.size(train))[:]]).tolist() # Only use N parts for training\n",
    "        eval_list.append([train, test, file_path_name_audio, file_path_name_eeg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_b = 0\n",
    "dct_params = dict()\n",
    "dct_params['train'] = eval_list[idx_b][0]\n",
    "dct_params['test'] = eval_list[idx_b][1]\n",
    "dct_params['file_path_name_audio'] = eval_list[idx_b][2]\n",
    "dct_params['file_path_name_eeg'] = eval_list[idx_b][3]\n",
    "dct_params['alpha_array']  = alpha_array \n",
    "dct_params['zscore'] = zscore \n",
    "dct_params['collect'] = collect \n",
    "dct_params['file_path_name_util'] = file_path_name_util \n",
    "dct_params['idx_ch'] = idx_ch \n",
    "dct_params['num_context'] = num_context \n",
    "dct_params['save_flag'] = save_flag\n",
    "dct_params['file_path_bciaud_shared'] = file_path_bciaud_shared\n",
    "dct_params['timestamp_time'] = timestamp_time\n",
    "dct_params['file_path_gridhome'] = file_path_gridhome\n",
    "dct_params['model_lsq'] = model_lsq\n",
    "dct_params['windsor_flag'] = windsor_flag\n",
    "dct_params['loss_type'] = loss_type\n",
    "\n",
    "# Debug\n",
    "#big_node(dct_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = len(eval_list)\n",
    "n_splits = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pe.Workflow(name=\"wf\")\n",
    "for idx_b in range(n_splits): \n",
    "    #if np.mod(idx_b, 1) == 0:\n",
    "    #    print(idx_b)  \n",
    "        \n",
    "    timestamp = '%s_%s' % (timestamp_time, \n",
    "                                 hashlib.md5((('').join(eval_list[idx_b][2]+eval_list[idx_b][3])).encode('utf')).hexdigest())\n",
    "\n",
    "    file_path_save = XXX_file_path_save_with_timestamp\n",
    "    \n",
    "    # Create the file_path_save here to avoid race conditions in the workflow\n",
    "    if not os.path.exists(file_path_save):\n",
    "        os.makedirs(file_path_save)\n",
    "        \n",
    "    node_big = pe.Node(niu.Function(input_names=['dct_params'],\n",
    "                                    output_names=['outputs'],\n",
    "                                    function=big_node),\n",
    "                                    name='big_node_%03d' % idx_b)\n",
    "   \n",
    "    dct_params = dict()\n",
    "    dct_params['train'] = eval_list[idx_b][0]\n",
    "    dct_params['test'] = eval_list[idx_b][1]\n",
    "    dct_params['file_path_name_audio'] = eval_list[idx_b][2]\n",
    "    dct_params['file_path_name_eeg'] = eval_list[idx_b][3]\n",
    "    dct_params['alpha_array']  = alpha_array \n",
    "    dct_params['zscore'] = zscore \n",
    "    dct_params['collect'] = collect \n",
    "    dct_params['file_path_name_util'] = file_path_name_util \n",
    "    dct_params['idx_ch'] = idx_ch \n",
    "    dct_params['num_context'] = num_context \n",
    "    dct_params['save_flag'] = save_flag  \n",
    "    dct_params['file_path_bciaud_shared'] = file_path_bciaud_shared     \n",
    "    dct_params['timestamp_time'] = timestamp_time \n",
    "    dct_params['file_path_gridhome'] = file_path_gridhome\n",
    "    dct_params['model_lsq'] = model_lsq\n",
    "    dct_params['windsor_flag'] = windsor_flag\n",
    "    dct_params['loss_type'] = loss_type\n",
    "    dct_params['cv_type'] = cv_type    \n",
    "\n",
    "    node_big.inputs.dct_params = dct_params    \n",
    "    wf.add_nodes([node_big])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.config['exeuction']['crashdump_dir'] = XXX_path_to_crashdumpdir\n",
    "wf.base_dir = XXX_path_to_base_dir\n",
    "\n",
    "wf.config['execution']['parameterize_dirs'] = False\n",
    "wf.config['execution']['poll_sleep_duration'] = 10\n",
    "wf.config['execution']['job_finished_timeout'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timestamp_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_local_flag = True\n",
    "#un_local_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if run_local_flag:\n",
    "    eg = wf.run() \n",
    "else: \n",
    "    eg = wf.run('SLURM', plugin_args={'sbatch_args': '--constraint=xeon-e5 --mem=15G'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
