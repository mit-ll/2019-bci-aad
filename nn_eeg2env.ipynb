{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This branch is the software release for the 2019 paper: https://www.nature.com/articles/s41598-019-47795-0\n",
    "\n",
    "See LICENSE.txt\n",
    "\n",
    "Copyright 2019 Massachusetts Institute of Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.io\n",
    "import scipy.io.wavfile\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import getpass\n",
    "#import seaborn as sns\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from importlib import reload \n",
    "from glob import glob\n",
    "import subprocess\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "np.random.seed(0) # for reproducibility tests\n",
    "torch.manual_seed(0) #for reproducibility tests\n",
    "\n",
    "## Perform auditory attention decoding using audio reconstruction or direct classification using neural networks\n",
    "#\n",
    "## About\n",
    "#  Greg Ciccarelli\n",
    "#  February 3, 2018\n",
    "#  March 22, 2018\n",
    "#  June 28, 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as niu\n",
    "import nipype.interfaces.io as nio\n",
    "\n",
    "import getpass\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the latest eeg and cochleogram for each of the subject folders\n",
    "collect = 'LL_HowTo_0DegreesSeparation'\n",
    "modality = 'neuroscan'\n",
    "#modality = 'dsi'\n",
    "\n",
    "#############################\n",
    "\n",
    "save_flag = True\n",
    "\n",
    "num_predict = 1\n",
    "\n",
    "hidden_size = 2 \n",
    "#hidden_size = 200\n",
    "\n",
    "num_ch_output = 1\n",
    "output_size = num_ch_output * num_predict \n",
    "\n",
    "slow_opt_flag = False\n",
    "#num_batch = int(1024) # bce\n",
    "num_batch = int(5)\n",
    "\n",
    "\n",
    "\n",
    "num_epoch = 2400 #paper\n",
    "num_epoch = 2\n",
    "\n",
    "learning_rate = 1e-3 #paper\n",
    "weight_decay = 0 #paper\n",
    "\n",
    "\n",
    "file_path_net = XXX_path_to_net \n",
    "\n",
    "# paper\n",
    "# dry, de taillez, 20190505112434, \n",
    "num_context=26\n",
    "file_name_net = '201806190841_1hid_b_tanh_b_htanh'\n",
    "file_name_get_data = '201807141456_get_noscale_dsi'\n",
    "loss_type = 'corr'\n",
    "\n",
    "# Dry, bce, 20190503142452, \n",
    "num_context=1000\n",
    "file_name_get_data = '201809272008_get_binary_conv_dry'\n",
    "file_name_net = '201809272028_binary_conv_dsi'\n",
    "loss_type = 'bce'\n",
    "\n",
    "# wet, bce, 20190504085917 \n",
    "num_context = 1000\n",
    "file_name_net = '201809262034_binary_conv'\n",
    "file_name_get_data = '201809262022_get_binary_conv'\n",
    "loss_type = 'bce'\n",
    "\n",
    "# wet, De taillez, 20190505101057, \n",
    "num_context = 26\n",
    "file_name_get_data = '201806221952_get_noscale'\n",
    "file_name_net = '201806190841_1hid_b_tanh_b_htanh'\n",
    "loss_type = 'corr'\n",
    "\n",
    "# wet ch sub, bce, 20190503211325, \n",
    "num_context = 1000\n",
    "file_name_get_data = '201905031434_get_data_bce_wet2dry'\n",
    "file_name_net = '201809272028_binary_conv_dsi'\n",
    "loss_type = 'bce'\n",
    "\n",
    "# wet ch sub, de taillez, 20190505110243, \n",
    "num_context = 26\n",
    "file_name_net = '201806190841_1hid_b_tanh_b_htanh'\n",
    "file_name_get_data = '201905031437_get_data_recon_wet2dry'\n",
    "loss_type = 'corr'\n",
    "\n",
    "file_path_name_net = os.path.join(file_path_net, file_name_net)\n",
    "\n",
    "\n",
    "file_path_name_get_data = XXX_path_and_name_to_get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.split(file_path_name_get_data)[0])\n",
    "module = __import__(os.path.split(file_path_name_get_data)[1])\n",
    "reload(module)\n",
    "load_data = getattr(module, 'load_data')\n",
    "get_data = getattr(module, 'get_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subj_folder_list = XXX_list_of_subj_folder_paths\n",
    "\n",
    "file_path_name_audio_list = []\n",
    "file_path_name_eeg_list = []\n",
    "for subj_folder in subj_folder_list[:]: #[:1]\n",
    "    try:\n",
    "        file_path_name_audio_list.append(sorted(glob(os.path.join(subj_folder, '*_Envelope100Hz.*')))[-1]) #. for real data  \n",
    "        file_path_name_eeg_list.append(sorted(glob(os.path.join(subj_folder, '*_EEGF*.*')))[-1])    \n",
    "    except:\n",
    "        print('-- missing --')\n",
    "        print(subj_folder)\n",
    "print(file_path_name_audio_list)\n",
    "print(file_path_name_eeg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "audio, eeg, audio_unatt = load_data(file_path_name_audio_list[0], file_path_name_eeg_list[0])\n",
    " \n",
    "print(audio.shape)\n",
    "print(eeg.shape)\n",
    "print(audio_unatt.shape)\n",
    "\n",
    "\n",
    "a = ~np.isnan(audio)\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.sum(a, axis=1));\n",
    "print(np.min(np.sum(a, axis=1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_keep_audioTime = np.sort(np.random.permutation(num_context)[:250]) # 250 LL\n",
    "\n",
    "dct_params = {'idx_keep_audioTime': idx_keep_audioTime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug get data\n",
    "idx_sample = 0\n",
    "X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=None, \n",
    "                             num_batch=None, idx_sample=idx_sample, \n",
    "                             num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "\n",
    "if X is not None:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(z_unatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    fig, ax = plt.subplots();\n",
    "    ax.plot(X.data.numpy()[100].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    fig, ax = plt.subplots();\n",
    "    ax.plot(y.data.numpy()[:100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug get data\n",
    "idx_sample = 0\n",
    "X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=None, \n",
    "                             num_batch=None, idx_sample=idx_sample, \n",
    "                             num_context=num_context, num_predict=num_predict, dct_params=None)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(z_unatt)\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.plot(y.data.numpy()[:100, 0:9]);\n",
    "fig, ax = plt.subplots();\n",
    "ax.plot(X.data.numpy()[:200, :10, 0]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize differences\n",
    "print(np.nanstd(X[:, 0, 0].data.numpy(), axis=0))\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.nanmean(np.nanmean(eeg, axis=2), axis=0));\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.nanmean(np.nanstd(eeg, axis=2), axis=0));\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.nanstd(eeg, axis=2)[:, 26]);\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.nanstd(audio, axis=1));\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.stem(np.nanstd(audio_unatt, axis=1));\n",
    "\n",
    "fig, ax = plt.subplots();\n",
    "ax.plot(audio[0][:500]);\n",
    "ax.plot(audio[-1][:500]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of data after removing nan's\n",
    "eeg_1ch = np.squeeze(eeg[:, 0, :])\n",
    "\n",
    "num_dur = np.nansum(~np.isnan(eeg_1ch), axis=1)\n",
    "print(num_dur)\n",
    "print(np.where(num_dur < num_context))\n",
    "print(np.mean(num_dur[num_dur >= num_context]*0.01))\n",
    "print(np.std(num_dur[num_dur >= num_context]* 0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required: Define the main processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_node(train, test, file_path_name_audio, file_path_name_eeg, dct_params):\n",
    "    \"\"\"Process data and make predictions.\n",
    "    \n",
    "    1. Unpack parameters, define model, define data\n",
    "    2. Training loop\n",
    "    3. Evaluation\n",
    "    4. Save\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    train : list\n",
    "        Integer list of training parts\n",
    "        \n",
    "    test : list\n",
    "        Integer test part\n",
    "        \n",
    "    file_path_name_audio : string\n",
    "        Full path and name of the audio mat file\n",
    "        \n",
    "    file_path_name_eeg : string\n",
    "        Full path and name of the eeg mat file\n",
    "        \n",
    "    dct_params: dict\n",
    "        Collection of auxillary parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    import scipy.io\n",
    "    import sklearn\n",
    "    import sklearn.preprocessing\n",
    "    import torch\n",
    "    from torch.autograd import Variable    \n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F   \n",
    "    import datetime\n",
    "    import time\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    import sys\n",
    "    from importlib import reload\n",
    "    import hashlib\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import nipype\n",
    "    \n",
    "    ################################################################\n",
    "    #      Unpack parameters, define model, define data\n",
    "    ################################################################    \n",
    "    # Setup the dnn, and create the monolithic block of data that will be used for training.\n",
    "    \n",
    "    def closs(x, y):\n",
    "        xbar = torch.mean(x)\n",
    "        ybar = torch.mean(y)\n",
    "        num = 1. / x.numel() * torch.dot(x-xbar, y-ybar)\n",
    "        denom = torch.std(x) * torch.std(y)\n",
    "        return -num / denom\n",
    "\n",
    "    num_context = dct_params['num_context']\n",
    "    num_predict = dct_params['num_predict']\n",
    "    num_epoch = dct_params['num_epoch']\n",
    "    idx_eeg = dct_params['idx_eeg']\n",
    "    save_flag = dct_params['save_flag']\n",
    "    file_path_save = dct_params['file_path_save']    \n",
    "    file_path_name_net= dct_params['file_path_name_net']   \n",
    "    input_size = dct_params['input_size']\n",
    "    hidden_size = dct_params['hidden_size']\n",
    "    output_size = dct_params['output_size']\n",
    "    num_batch = dct_params['num_batch']\n",
    "    learning_rate = dct_params['learning_rate']\n",
    "    weight_decay = dct_params['weight_decay']\n",
    "    loss_type = dct_params['loss_type']\n",
    "    collect = dct_params['collect']\n",
    "    idx_split = dct_params['idx_split']\n",
    "    random_seed_flag = dct_params['random_seed_flag']\n",
    "    slow_opt_flag = dct_params['slow_opt_flag']\n",
    "\n",
    "    \n",
    "    if random_seed_flag:\n",
    "        np.random.seed(idx_split)\n",
    "        torch.manual_seed(idx_split)\n",
    "    else:\n",
    "        np.random.seed(0)\n",
    "        torch.manual_seed(0)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic=True        \n",
    "    \n",
    "    # Load and preprocess the data\n",
    "    file_path_name_get_data = dct_params['file_path_name_get_data']\n",
    "    sys.path.append(os.path.split(file_path_name_get_data)[0])\n",
    "    module = __import__(os.path.split(file_path_name_get_data)[1])\n",
    "    reload(module)\n",
    "    get_data = getattr(module, 'get_data')\n",
    "    load_data = getattr(module, 'load_data')\n",
    "    \n",
    "    \n",
    "    # Comment out in order to have the same val set and therefore the same train set \n",
    "    # between runs\n",
    "    #train = np.asarray(train)[np.random.permutation(len(train))].tolist()\n",
    "    if 1:\n",
    "        valset = train[-2:]\n",
    "        print(valset)\n",
    "        train = train[:-2]\n",
    "        print(train)\n",
    "    else:\n",
    "        valset = []\n",
    "    \n",
    "    # path to folder containing the class.py module\n",
    "    sys.path.append(os.path.split(file_path_name_net)[0])\n",
    "    module = __import__(os.path.split(file_path_name_net)[1]) \n",
    "    reload(module) # handle case of making changes to the module- forces reload\n",
    "    NN = getattr(module, 'NN')\n",
    "\n",
    "    model = NN(input_size, hidden_size, output_size)\n",
    "\n",
    "    num_val = len(valset)\n",
    "    num_tr = len(train)     \n",
    "    \n",
    "    params = model.state_dict()\n",
    "\n",
    "    if loss_type == 'mse':\n",
    "        loss_fn = nn.MSELoss(size_average=True) # True = MSE vs False = sum squared\n",
    "    elif loss_type == 'corr':\n",
    "        loss_fn = closs\n",
    "    elif loss_type == 'bce':\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    if False: #torch.cuda.is_available():\n",
    "        cuda_flag = True\n",
    "        model.cuda()\n",
    "        print('Using CUDA')\n",
    "    else:\n",
    "        print('No CUDA')\n",
    "        cuda_flag = False\n",
    "\n",
    "    loss_history = np.nan * np.zeros(num_epoch)\n",
    "    loss_val_history = np.nan * np.zeros(num_epoch)\n",
    "    model.train() # Turn on dropout, batchnorm\n",
    "    #model.eval()\n",
    "    \n",
    "    audio, eeg, audio_unatt = load_data(file_path_name_audio, file_path_name_eeg, train=train)\n",
    "        \n",
    "    idx_eeg = None\n",
    "    idx_sample = train[0]\n",
    "    X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=idx_eeg, \n",
    "                                 num_batch=None, idx_sample=idx_sample, \n",
    "                                 num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "    X_all = X\n",
    "    y_all = y\n",
    "\n",
    "    for idx_sample in train[1:]: #train[1:] [1:2]\n",
    "        print(idx_sample)    \n",
    "        X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=idx_eeg, \n",
    "                                     num_batch=None, idx_sample=idx_sample, \n",
    "                                     num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "        if X is not None:\n",
    "            X_all = torch.cat((X_all, X), dim=0)\n",
    "            y_all = torch.cat((y_all, y), dim=0)\n",
    "    print(X_all.shape)\n",
    "    \n",
    "    # Outside the loop to only form conv matrix once\n",
    "    idx_val_sample = valset[0]\n",
    "    Xval, yval, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=idx_eeg, \n",
    "                                 num_batch=None, idx_sample=idx_val_sample, \n",
    "                                 num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "    \n",
    "    ################################################################\n",
    "    #              Training loop\n",
    "    ################################################################\n",
    "    # Iterate over the dataset a fixed number of times or until an early stopping condition is reached.\n",
    "    # Randomly select a new batch of training at each iteration\n",
    "    \n",
    "    example_val_y = np.nan\n",
    "    example_val_z_unatt = np.nan\n",
    "    example_val_yhat = np.nan\n",
    "    idx_sample_list = np.nan * np.ones(num_epoch)\n",
    "    idx_sample = train[0] # Initialize to the first training part\n",
    "    idx_train = 0\n",
    "    early_stop_flag = False\n",
    "    early_stop_counter = 0\n",
    "    start = time.perf_counter()\n",
    "    t_start = datetime.datetime.now()    \n",
    "    print(t_start)\n",
    "    while (idx_train < num_epoch) and (not early_stop_flag):       \n",
    "        if np.mod(idx_train, num_epoch/10) == 0:\n",
    "            print('epoch %d ' % idx_train)\n",
    "            end = time.perf_counter()\n",
    "            t_end = datetime.datetime.now()\n",
    "            print('Time per epoch %2.5f ticks' % ((end - start)/(num_epoch/10)))\n",
    "            print((t_end - t_start)/(num_epoch/10))\n",
    "            start = time.perf_counter()\n",
    "            t_start = datetime.datetime.now()           \n",
    "            print(t_start)                        \n",
    "            \n",
    "        idx_keep = np.random.permutation(X_all.data.size(0))[:num_batch]\n",
    "        idx_keep = torch.from_numpy(idx_keep).type('torch.LongTensor')\n",
    "        X_audio = X_all[idx_keep]\n",
    "        y = y_all[idx_keep]                      \n",
    "        #X_audio = X_audio + Variable(0. * torch.randn(X_audio.shape))    # Data augmentation via noise                  \n",
    "\n",
    "        #print('-- got data--')\n",
    "        if X_audio is not None:\n",
    "            model.zero_grad()\n",
    "            #print('-pre forward-')\n",
    "            if cuda_flag:\n",
    "                y = y.cuda()\n",
    "                output = model.forward(X_audio.cuda())\n",
    "            else:\n",
    "                output = model.forward(X_audio)\n",
    "\n",
    "            loss = loss_fn(output.view(-1), y.view(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #print('opt zeroed')\n",
    "            loss.backward()\n",
    "            #print('loss.backward done')\n",
    "            optimizer.step()\n",
    "            loss_flag = 1\n",
    "\n",
    "            if cuda_flag:\n",
    "                loss = loss.cpu()\n",
    "                output = output.cpu()\n",
    "                y = y.cpu()\n",
    "            loss_history[idx_train] = loss_flag * loss.data.numpy()\n",
    "            \n",
    "            if False: #loss_history[idx_train] < 0.09:\n",
    "                early_stop_flag = True\n",
    "                print(\"early_stop!\")\n",
    "            \n",
    "            # Check validation set performance\n",
    "            if (len(valset) > 0) and (np.mod(idx_train, 1) == 0): #50\n",
    "                #print('--- val check ---')\n",
    "                model.eval()\n",
    "\n",
    "                idx_keep = np.sort(np.random.permutation(Xval.data.size(0))[:num_batch])\n",
    "                idx_keep = torch.from_numpy(idx_keep).type('torch.LongTensor')\n",
    "                X = Xval[idx_keep]\n",
    "                y = yval[idx_keep]  \n",
    "                \n",
    "                if cuda_flag:\n",
    "                    y_att = model.forward(X.cuda())\n",
    "                else:\n",
    "                    y_att = model.forward(X)\n",
    "\n",
    "                if cuda_flag:\n",
    "                    stat_1 =  loss_fn(y_att.view(-1), y.cuda().view(-1))\n",
    "                else:\n",
    "                    stat_1 = loss_fn(y_att.view(-1), y.view(-1))\n",
    "                    stat_1 = stat_1.data.numpy()\n",
    "                loss_val_history[idx_train] = stat_1\n",
    "                model.train()\n",
    "                \n",
    "                example_val_y = y.cpu().data.numpy()\n",
    "                example_val_yhat = y_att.cpu().data.numpy()\n",
    "                \n",
    "            idx_train = idx_train + 1\n",
    "    \n",
    "    print('-- done training --')\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    ################################################################\n",
    "    #              Evaluation\n",
    "    ################################################################\n",
    "    # Test on the train set, then test on the test set.    \n",
    "    \n",
    "    if True:\n",
    "        example_tr_y = []\n",
    "        example_tr_yhat = []\n",
    "        example_tr_unatt = []\n",
    "        for idx_tr in train[:1]:\n",
    "            X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=idx_eeg, \n",
    "                                         num_batch=num_batch, idx_sample=idx_tr, \n",
    "                                         num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "            if X is not None:\n",
    "                model.eval()\n",
    "                if cuda_flag:\n",
    "                    y_att = model.forward(X.cuda())\n",
    "                else:\n",
    "                    y_att = model.forward(X)  \n",
    "                example_tr_y.append(y.cpu().data.numpy())\n",
    "                example_tr_yhat.append(y_att.cpu().data.numpy())\n",
    "            if z_unatt is None:\n",
    "                example_tr_unatt.append(np.array(np.nan))\n",
    "            else:\n",
    "                example_tr_unatt.append(z_unatt.data.numpy())\n",
    "        \n",
    "    if True:\n",
    "        X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=idx_eeg, \n",
    "                                     num_batch=None, idx_sample=test[0], \n",
    "                                     num_context=num_context, num_predict=num_predict, dct_params=dct_params)\n",
    "        \n",
    "        if X is not None:\n",
    "            model.eval()\n",
    "            if cuda_flag:\n",
    "                y_att = model.forward(X.cuda())\n",
    "            else:\n",
    "                y_att = model.forward(X)  \n",
    "            example_te_y = y.cpu().data.numpy()[None, :]\n",
    "            example_te_yhat = y_att.cpu().data.numpy()[None, :]\n",
    "        else:\n",
    "            example_te_y = np.nan\n",
    "            example_te_yhat = np.nan\n",
    "        if z_unatt is None:\n",
    "            example_te_unatt = np.array([np.nan])\n",
    "        else:\n",
    "            example_te_unatt = z_unatt.data.numpy()[None, :]\n",
    "            \n",
    "    ################################################################\n",
    "    #              Save\n",
    "    ################################################################ \n",
    "    # Save network parameters and outputs            \n",
    "    \n",
    "    ver_list = []\n",
    "    for v in [torch, np, scipy, nipype]:\n",
    "        ver_list.append(v.__name__ + \"_\" + v.__version__)   \n",
    "    ver_list.append('python_' + sys.version)    \n",
    "\n",
    "    if save_flag:\n",
    "        dct_all = {**{'loss': loss_history, 'train': train, 'test': test, \n",
    "                             'file_path_name_audio': file_path_name_audio, \n",
    "                              'file_path_name_eeg': file_path_name_eeg, \n",
    "                              'valset': valset, \n",
    "                             'loss_val_history': loss_val_history,\n",
    "                             'idx_sample_list': idx_sample_list,\n",
    "                             'yValAtt': example_val_y,\n",
    "                             'yValHat': example_val_yhat,\n",
    "                             'yValUna': example_val_z_unatt,\n",
    "                             'yTrainAtt': example_tr_y,\n",
    "                             'yTrainHat': example_tr_yhat,\n",
    "                             'yTrainUna': example_tr_unatt,\n",
    "                             'yTestAtt': example_te_y,\n",
    "                             'yTestHat': example_te_yhat,\n",
    "                             'yTestUna': example_te_unatt,\n",
    "                             'envTestAtt': example_te_y, #output api compatible\n",
    "                             'envHatAtt': example_te_yhat, #output api compatible\n",
    "                             'envTestUna': example_te_unatt, #output api compatible\n",
    "                             'subjID': re.search('Subj_(\\d+)_', file_path_name_audio).group(1),#output api compatible\n",
    "                             'ver_list': ver_list                      \n",
    "                       },      \n",
    "                           \n",
    "                          **dct_params}        \n",
    "        \n",
    "        hashstr = ''\n",
    "        for key, val in {**{'train': train}, **dct_params}.items():\n",
    "            if type(val) is str:\n",
    "                hashstr = hashstr + key + val\n",
    "            elif type(val) in [float, int]:\n",
    "                hashstr = hashstr + key + str(val)\n",
    "            elif type(val) in [list]:\n",
    "                if type(val[0]) is str:\n",
    "                    hashstr = hashstr + key + ','.join(val)\n",
    "                elif type(val[0]) in [float, int]:\n",
    "                    hashstr = hashstr + key + ','.join([str(i) for i in val])\n",
    "        hexstamp = hashlib.md5(hashstr.encode('utf')).hexdigest()\n",
    "        \n",
    "        now_str = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        file_path_name_checkpoint = os.path.join(file_path_save, \n",
    "                                                 'checkpoint_eeg2env_%s_%s.pt' \n",
    "                                                 % (hexstamp, now_str))\n",
    "        torch.save({'state_dict': model.state_dict()}, file_path_name_checkpoint)\n",
    "        \n",
    "        print(file_path_name_checkpoint)\n",
    "        # Replace all None elements of dict with NaN before saving to avoid save fail.\n",
    "        for key, val in dct_all.items():\n",
    "            if val is None:\n",
    "                dct_all[key] = np.nan\n",
    "        scipy.io.savemat(os.path.join(file_path_save, \n",
    "                                      'checkpoint_eeg2env_%s_%s.mat' \n",
    "                                       % (hexstamp, now_str)), \n",
    "                                      dct_all)\n",
    "           \n",
    "    model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required: Define all data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_time = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "# :9 same AM or PM run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for file_path_name_audio, file_path_name_eeg in zip(file_path_name_audio_list, file_path_name_eeg_list):\n",
    "    print(file_path_name_audio)\n",
    "    audio, eeg, audio_unatt = load_data(file_path_name_audio, file_path_name_eeg)\n",
    "\n",
    "    # exhaustive\n",
    "    full_set = audio.shape[0]\n",
    "    #full_set = 10 # debug, 4\n",
    "    \n",
    "    X, y, z_unatt = get_data(audio, eeg, audio_unatt=audio_unatt, idx_eeg=None, \n",
    "                                 num_batch=None, idx_sample=0, \n",
    "                                 num_context=num_context, num_predict=num_predict, dct_params=dct_params)    \n",
    "\n",
    "    input_size = np.prod(X.shape[1:]) \n",
    "    print(input_size)\n",
    "    for test in range(full_set): \n",
    "    #for test in np.random.permutation(full_set).tolist(): #If running less than a full set of splits and want to see different test partitions\n",
    "        train = sorted(list(set(range(full_set)) - set([test])))\n",
    "        eval_list.append([train, [test], file_path_name_audio, file_path_name_eeg, input_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test stability of training\n",
    "## Can the identical network with identical inputs recover the same performance with/without different random seeds during initialization/training/optimization?\n",
    "## DEBUG for Stability check\n",
    "## Take eval list, first item, copy N times\n",
    "## These should be identical runs of the network\n",
    "\n",
    "eval_list = [eval_list[0] for i in range(len(eval_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required: Define how many of the data splits to actually run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = len(eval_list)\n",
    "#n_splits = 5\n",
    "#n_splits = 2\n",
    "#n_splits = 3\n",
    "n_splits = 1\n",
    "\n",
    "random_seed_flag = True\n",
    "#random_seed_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = pe.Workflow(name=\"wf\")\n",
    "for idx_b in range(n_splits):         \n",
    "    timestamp = '%s_%s' % (timestamp_time, \n",
    "                                 hashlib.md5((('').join(eval_list[idx_b][2]+eval_list[idx_b][3])).encode('utf')).hexdigest())\n",
    "\n",
    "    file_path_save = XXX_file_path_save_with_timestamp\n",
    "    \n",
    "    # Create the file_path_save here to avoid race conditions in the workflow\n",
    "    if not os.path.exists(file_path_save):\n",
    "        os.makedirs(file_path_save)\n",
    "        \n",
    "    # Remember, it is MUCH faster to submit lightweight arguments to a node than to submit the entire dataset.\n",
    "    # That's why the dataset is loaded inside big_node.         \n",
    "    node_big = pe.Node(niu.Function(input_names=['train', 'test', \n",
    "                                                 'file_path_name_audio', \n",
    "                                                 'file_path_name_eeg', \n",
    "                                                 'dct_params'],\n",
    "                                    output_names=['outputs'],\n",
    "                                    function=big_node),\n",
    "                                    name='big_node_%03d' % idx_b)\n",
    "   \n",
    "    dct_params = {'idx_eeg': np.nan * np.ones(eeg.shape[1]), \n",
    "                  'num_context': num_context,\n",
    "                  'num_predict' : num_predict,\n",
    "                  'idx_split': idx_b,\n",
    "                  'timestamp': timestamp, \n",
    "                  'file_path_save': file_path_save,\n",
    "                  'file_path_name_get_data': file_path_name_get_data,\n",
    "                  'save_flag':save_flag,  \n",
    "                  'num_epoch': num_epoch,\n",
    "                  'file_path_name_net': file_path_name_net,\n",
    "                  'input_size': eval_list[idx_b][4],\n",
    "                  'hidden_size': hidden_size,\n",
    "                  'output_size': output_size,\n",
    "                  'num_batch': num_batch,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'weight_decay': weight_decay,\n",
    "                  'loss_type': loss_type,\n",
    "                  'num_ch_output': num_ch_output,\n",
    "                  'collect': collect,\n",
    "                  'idx_keep_audioTime': idx_keep_audioTime, \n",
    "                  'random_seed_flag': random_seed_flag, \n",
    "                  'slow_opt_flag': slow_opt_flag}   \n",
    "    \n",
    "    node_big.inputs.train = eval_list[idx_b][0] #train\n",
    "    node_big.inputs.test = eval_list[idx_b][1] #test\n",
    "    \n",
    "    node_big.inputs.file_path_name_audio = eval_list[idx_b][2] #file_path_name_audio\n",
    "    node_big.inputs.file_path_name_eeg = eval_list[idx_b][3] #file_path_name_eeg\n",
    "\n",
    "    node_big.inputs.dct_params = dct_params    \n",
    "    wf.add_nodes([node_big])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Test main processing function\n",
    "## Don't use nipype, just run the function\n",
    "\n",
    "stats = big_node(train, [test], file_path_name_audio, file_path_name_eeg, dct_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required: Main Proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.config['execution']['crashdump_dir'] = XXX_path_to_crashdumpdir\n",
    "wf.base_dir = XXX_path_to_base_dir\n",
    "\n",
    "wf.config['execution']['parameterize_dirs'] = False\n",
    "wf.config['execution']['poll_sleep_duration'] = 10\n",
    "wf.config['execution']['job_finished_timeout'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_local_flag = True\n",
    "run_local_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_local_flag:\n",
    "    eg = wf.run() \n",
    "else: \n",
    "    #eg = wf.run('SLURM', plugin_args={'sbatch_args': '-p gpu --gres=gpu:tesla:2 --constraint=xeon-e5 --mem=15G'})\n",
    "    eg = wf.run('SLURM', plugin_args={'sbatch_args': '--constraint=xeon-e5 --exclusive -O'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Look at network parameters from a saved output fileÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at params\n",
    "module = __import__(os.path.split(file_path_name_net)[1])\n",
    "reload(module)\n",
    "NN = getattr(module, 'NN')\n",
    "\n",
    "file_path_name_checkpoint = XXX_path_to_checkpoint\n",
    "\n",
    "model = NN(input_size, hidden_size, output_size)\n",
    "checkpoint = torch.load(file_path_name_checkpoint)\n",
    "model.load_state_dict(checkpoint['state_dict']) \n",
    "model.eval()\n",
    "\n",
    "#a = list(model.parameters())\n",
    "\n",
    "#[print(a[i]) for i in range(len(a))]\n",
    "\n",
    "p = nn.utils.parameters_to_vector(model.parameters())\n",
    "\n",
    "p[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
